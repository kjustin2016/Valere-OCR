import os
import boto3
import json
import time
import re
from dotenv import load_dotenv
import trp.trp2 as t2
from tabulate import tabulate
import psycopg2

# Load environment variables
load_dotenv()

# Initialize AWS clients
aws_access_key_id = os.getenv("AWS_ACCESS_KEY_ID")
aws_secret_access_key = os.getenv("AWS_SECRET_ACCESS_KEY")
aws_region = os.getenv("AWS_REGION")


db_endpoint = os.getenv("DB_ENDPOINT")
db_port = os.getenv("DB_PORT")
db_name = os.getenv("DB_NAME")
db_user = os.getenv("DB_USER")
db_pass = os.getenv("DB_PASS")

s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)
textract = boto3.client('textract', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key, region_name=aws_region)

# Define the entity tag to search for
entity_tag = "156426b875242d1ace35be6af661e839"  # Replace with the actual entity tag

def get_s3_bucket_object_by_tag(bucket, tag):
    paginator = s3.get_paginator('list_objects_v2')
    operation_parameters = {'Bucket': bucket}
    page_iterator = paginator.paginate(**operation_parameters)

    for page in page_iterator:
        if 'Contents' in page and page['Contents']:
            for item in page['Contents']:
                head_object = s3.head_object(Bucket=bucket, Key=item['Key'])
                if 'ETag' in head_object and head_object['ETag'].strip('"') == tag:
                    return item['Key']
    
    print(f"No object found with tag: {tag}")
    return None

def textract_analyze_with_queries(bucket, object_key):
    try:
        # Start asynchronous document analysis with queries
        response = textract.start_document_analysis(
            DocumentLocation={'S3Object': {'Bucket': bucket, 'Name': object_key}},
            FeatureTypes=["QUERIES", "SIGNATURES", "FORMS"],
            QueriesConfig={"Queries": [
                {"Text": "What is the customer name?", "Alias": "SIGNER_NAME"},
                {"Text": "What is the date signed?", "Alias": "SIGNING_DATE"}
            ]}
        )
        
        job_id = response['JobId']
        print(f"Started asynchronous job for PDF with JobId: {job_id}")

        # Poll for job completion
        while True:
            result = textract.get_document_analysis(JobId=job_id)
            status = result['JobStatus']
            if status in ['SUCCEEDED', 'FAILED']:
                break
            print("Waiting for Textract to complete the analysis...")
            time.sleep(5)

        if status == 'SUCCEEDED':
            # Get all pages from the job
            pages = []
            next_token = None
            
            while True:
                if next_token:
                    result = textract.get_document_analysis(JobId=job_id, NextToken=next_token)
                else:
                    result = textract.get_document_analysis(JobId=job_id)
                
                pages.append(result)
                
                if 'NextToken' in result:
                    next_token = result['NextToken']
                else:
                    break
            
            # Combine all pages into a single response
            combined_response = pages[0]  # Start with the first page
            if len(pages) > 1:
                for page in pages[1:]:
                    combined_response['Blocks'].extend(page['Blocks'])
            
            # Extract raw text for pattern matching
            raw_text = ""
            for block in combined_response.get('Blocks', []):
                if block.get('BlockType') in ['LINE'] and 'Text' in block:
                    raw_text += block.get('Text', '') + "\n"
            
            print("Raw text extracted for pattern matching")
            
            return combined_response, raw_text
        else:
            raise ValueError("Textract document analysis failed.")

    except Exception as e:
        print(f"Error in textract_analyze_with_queries: {e}")
        return None, None

def detect_signature(response):
    """Check if a signature is present in the document"""
    try:
        blocks = response.get('Blocks', [])
        
        # Look for SIGNATURE block type
        for block in blocks:
            if block.get('BlockType') == 'SIGNATURE':
                return "Yes"
        
        # If no SIGNATURE block type was found, try alternative detection methods
        # Look for a page that likely contains a signature (like page 4 in your document)
        raw_text = ""
        for block in blocks:
            if block.get('BlockType') in ['LINE'] and 'Text' in block:
                raw_text += block.get('Text', '') + "\n"
                
        # Check for signature indicators like page with very little text
        # or pages that come after "Signed by customer" text
        if "Signed by customer:" in raw_text:
            # If we found the "Signed by customer" text and there's a page after it,
            # it likely contains the signature
            return "Yes"
                
        return ""
        
    except Exception as e:
        print(f"Error detecting signature: {e}")
        return "Error"

def extract_name_and_date_by_pattern(raw_text):
    """Extract name and date using regex patterns specifically for the document format"""
    name = None
    date = None
    
    # Split the text into lines
    lines = raw_text.split('\n')
    last_15_lines = lines[-15:]
    
    # Process each line individually to look for exact pattern matches
    for line in last_15_lines:
        # Look for customer name line
        if "Signed by customer:" in line:
            # Extract just the name part after the label
            name_part = line.split("Signed by customer:")[-1].strip()
            
            # Validate the name
            excluded_names = ["Jammie Shannon", "David Sanders"]
            if name_part in excluded_names or len(name_part) < 3:
                print(f"Found but rejected invalid name: {name_part}")
            else:
                name = name_part
                print(f"Found valid name by pattern: {name}")
        
        # Look for date line - using regex to capture the full date pattern
        date_match = re.search(r'Date\s*:?\s*(\d{1,2}/\d{1,2}/\d{4}\s+\d{1,2}:\d{2}\s*(?:AM|PM|CMT)?)', line)
        if date_match:
            date = date_match.group(1).strip()
            print(f"Found date by pattern: {date}")
            continue
            
        # Backup pattern just looking for a date format anywhere in the line
        date_backup_match = re.search(r'(\d{1,2}/\d{1,2}/\d{4}\s+\d{1,2}:\d{2}\s*(?:AM|PM|CMT)?)', line)
        if date_backup_match and not date:  # Only use backup if we haven't found a date yet
            date = date_backup_match.group(1).strip()
            print(f"Found date by backup pattern: {date}")
    
    return {"name": name, "date": date}

def calculate_confidence_score(result_dict):
    """
    Calculate a confidence score based on how many data points were successfully extracted.
    The score is out of 3, with one point for each successfully extracted field:
    PatientName, Date, and SignaturePresent.
    
    Args:
        result_dict (dict): Dictionary containing the extracted fields
        
    Returns:
        int: Confidence score from 0 to 3
    """
    score = 0
    
    # Check if PatientName is present and not empty
    if result_dict.get("PatientName"):
        score += 1
    
    # Check if Date is present and not empty
    if result_dict.get("Date"):
        score += 1
    
    # Check if SignaturePresent is present and has a "Yes" value
    if result_dict.get("SignaturePresent") == "Yes":
        score += 1
    
    return score

if __name__ == "__main__":
    bucket_name = "capstone-intelligent-document-processing"
    
    # Use the entity tag to get the object key
    object_key = get_s3_bucket_object_by_tag(bucket_name, entity_tag)
    
    if object_key:
        # Get Textract analysis with queries
        textract_response, raw_text = textract_analyze_with_queries(bucket_name, object_key)
        
        if textract_response and raw_text:
            
            # Parse the response using trp2 library
            d = t2.TDocumentSchema().load(textract_response)
            page = d.pages[0]
            
            # Get query answers
            query_answers = d.get_query_answers(page=page)
            
            # Check for signature
            signature_present = detect_signature(textract_response)
            
            # Extract by pattern
            pattern_extraction = extract_name_and_date_by_pattern(raw_text)
            
            # Get name and date from different methods
            name = None
            date = None
            
            # First try pattern extraction (highest priority)
            if pattern_extraction["name"]:
                name = pattern_extraction["name"]
                # Extra validation - name should not be a contact name
                if name in ["Jammie Shannon", "David Sanders"]:
                    name = None
            
            if pattern_extraction["date"]:
                date = pattern_extraction["date"]
            
            # Then try Textract queries if patterns didn't find anything
            if not name:
                for qa in query_answers:
                    if qa[1] == "SIGNER_NAME" and qa[2]:
                        candidate_name = qa[2].strip()
                        # Validate against known non-customer names
                        if candidate_name not in ["Jammie Shannon", "David Sanders"]:
                            name = candidate_name
                            break
            
            if not date:
                for qa in query_answers:
                    if qa[1] == "SIGNING_DATE" and qa[2]:
                        date = qa[2]
                        break
            
            # Create result dictionary
            result_dict = {
                "PatientName": name if name else "",
                "Date": date if date else "",
                "SignaturePresent": signature_present
            }

            # Calculate confidence score and add it to the result dictionary
            confidence_score = calculate_confidence_score(result_dict)
            result_dict["ConfidenceScore"] = round(confidence_score / 3, 2)

            # Output as JSON to console
            json_output = json.dumps(result_dict, indent=4)
            print("\nExtracted Information (JSON):")
            print(json_output)
            
            # Save to file
            with open("extracted_info.json", "w") as json_file:
                json_file.write(json_output)
                
        else:
            print("Failed to extract data from document.")
    else:
        print("No documents found with the specified tag.")
    
def get_db_connection():
    return psycopg2.connect(host=db_endpoint,
                            port=db_port,
                            database=db_name,
                            user=db_user,
                            password=db_pass,
                            sslrootcert="SSLCERTIFICATE")


# Example to add an entry in the documents table

# object_key = "facesheet_123123_so_many_other_things"

# object_json = {
#     "patient": {"name":"test_name"}
# }

# connection = get_db_connection()
# cursor = connection.cursor()
# cursor.execute("INSERT INTO documents (document_key, json) VALUES (%s, %s)",(object_key, json.dumps(object_json)))
# connection.commit()
